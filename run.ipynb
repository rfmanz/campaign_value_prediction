{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "sys.path.append('./utils')\n",
    "from amg_utils import * \n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.models import LightGBMModel, LinearRegressionModel, RegressionModel, XGBModel, CatBoostModel \n",
    "from sklearn.linear_model import BayesianRidge, Ridge \n",
    "\n",
    "from darts.utils import missing_values\n",
    "from darts.dataprocessing.transformers import StaticCovariatesTransformer\n",
    "from darts.explainability.shap_explainer import ShapExplainer\n",
    "from darts.metrics import rmse, mae\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sql \n",
    "\n",
    "# fb_tonic_daily_perf_query = \"\"\"   \n",
    "   \n",
    "#    select    \n",
    "#    a.eventdate,\n",
    "#    b.fb_created,  \n",
    "\n",
    "\n",
    "#    a.buyer_initials,\n",
    "#    a.buyer_name,\n",
    "#    a.account_currency,\n",
    "#    a.account_id,\n",
    "#    a.account_name,\n",
    "#    a.ad_id, \n",
    "#    a.ad_name,\n",
    "#    a.adset_id,\n",
    "#    a.adset_name,\n",
    "#    a.campaign_id,\n",
    "#    a.campaign_name,\n",
    "#    --d.keyword, \n",
    "#    a.job_type,\n",
    "#    COALESCE(a.fb_clicks_all, 0) as fb_clicks_all,\n",
    "#    COALESCE(a.fb_impressions, 0) as fb_impressions,\n",
    "#    COALESCE(a.fb_leads, 0) as fb_leads,\n",
    "#    COALESCE(a.fb_link_click, 0) as fb_link_click,\n",
    "#    a.fb_spend,\n",
    "#    a.rev_clicks,\n",
    "#    a.gross_revenue,\n",
    "#    a.net_revenue,\n",
    "#    a.fb_clicks_all / COALESCE(NULLIF(a.fb_impressions, 0), 1) as buy_side_ctr,\n",
    "#    a.net_revenue / COALESCE(NULLIF(a.fb_spend, 0), 1) as roas,\n",
    "#    a.net_revenue / COALESCE(NULLIF(a.fb_clicks_all, 0), 1) as rpc,\n",
    "#    (a.fb_spend / COALESCE(NULLIF(a.fb_impressions, 0), 1))*1000 as buy_side_cpm,\n",
    "#    a.fb_spend / COALESCE(NULLIF(a.fb_clicks_all, 0), 1) as cpc,\n",
    "#    a.net_revenue / COALESCE(NULLIF(a.rev_clicks, 0), 1) as rpp,\n",
    "#    a.fb_spend / COALESCE(NULLIF(a.rev_clicks, 0), 1) as cpp,\n",
    "#    a.net_revenue - a.fb_spend as contrib, \n",
    "   \n",
    "  \n",
    "#    --b.end_time, \n",
    "#    b.budget,    \n",
    "#    b.budget_type,   \n",
    "#    b.status, \n",
    "\n",
    "#    c.devices,\n",
    "#    c.countries,\n",
    "#    c.network,\n",
    "#    targeting_json:age_max::string AS age_max,\n",
    "#    targeting_json:age_min::string AS age_min,\n",
    "#    targeting_json:facebook_positions::string AS facebook_positions,\n",
    "#    targeting_json:locales::string AS locales,\n",
    "#    c.adset_schedule,   \n",
    "#    c.lifetime_budget\n",
    "\n",
    "#    from PRODUCTION.BD_S2CINTERNAL.v_cm_fb_tonic_daily_combine a \n",
    "#    left join SEM_TOOLS.cm_fb_campaign_management.ad_set_latest b on a.adset_id = b.id  and a.campaign_id = b.campaign_id and a.adset_name = b.name\n",
    "#    left join PRODUCTION.BD_S2CINTERNAL.V_FACEBOOK_ADSET_METADATA c on a.adset_id = c.id and a.eventdate = c.event_date\n",
    "#   -- left join PRODUCTION.BD_S2CINTERNAL.V_CM_TONIC_KEYWORD_DATA d on d.fb_campaign_name = a.campaign_name\n",
    "#    where a.job_type= 'final'    \n",
    "#      and a.buyer_initials = 'GN'   \n",
    "\n",
    "#   order by  ad_id asc , eventdate asc  \n",
    "#    \"\"\"\n",
    "# fb_tonic_daily_perf = eq(fb_tonic_daily_perf_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# fb_tonic_daily_perf = pd.read_csv(\"fb_tonic_daily_perf_query.csv\", index_col=0, parse_dates=['eventdate'])\n",
    "\n",
    "# # Crate campaign duration in days variable\n",
    "# fb_tonic_daily_perf.insert(2, 'campaign_duration', fb_tonic_daily_perf.groupby('campaign_id')['eventdate'].transform(lambda x: (x.max() - x.min()).days))\n",
    "\n",
    "# # Create campaign end date variable\n",
    "# fb_tonic_daily_perf.insert(2, 'campaign_end_date', fb_tonic_daily_perf.groupby('campaign_id')['eventdate'].transform(\"max\"))\n",
    "\n",
    "# # Filter out campaigns with less than {min_campaign_duration} days duration\n",
    "min_campaign_duration = 4 \n",
    "# series = fb_tonic_daily_perf[fb_tonic_daily_perf['campaign_duration'] > 4].copy()\n",
    "# series.ad_id = series.ad_id.astype('str')\n",
    "\n",
    "# static_cols = [      \n",
    "# \"network\",\n",
    "# \"devices\"]     \n",
    "\n",
    "# def one_hot_encode(df, cols):\n",
    "#     encoded = pd.get_dummies(df[cols])\n",
    "#     df = df.drop(columns=cols, axis=1)\n",
    "#     df = pd.concat([df, encoded], axis=1)\n",
    "#     return df\n",
    "\n",
    "# series =  one_hot_encode(series, static_cols)\n",
    "\n",
    "series = pd.read_csv('series.csv', index_col=0, parse_dates=['eventdate'], dtype={'ad_id': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: gn_fb_tonic\n",
      "Total number of campaigns: 146\n",
      "Min eventdate: 2024-01-17\n",
      "Max eventdate: 2024-02-13\n",
      "Days between min and max eventdate: 27\n",
      "\n",
      "Duration of campaigns (filtered to only campaigns of 4 or more days): \n",
      "   campaign_duration (days)  count\n",
      "0                         5      3\n",
      "1                         6     16\n",
      "2                         7     42\n",
      "3                         8     71\n",
      "4                         9      9\n",
      "5                        10      2\n",
      "6                        15      1\n",
      "7                        16      1\n",
      "8                        21      1\n",
      "\n",
      "Mean campaign duration: 7.2 days\n",
      "\n",
      "Number of campaigns created per date: \n",
      "   fb_created_date  count\n",
      "0      2024-01-18      9\n",
      "1      2024-01-19     13\n",
      "2      2024-01-24     39\n",
      "3      2024-01-25     24\n",
      "4      2024-01-26     22\n",
      "5      2024-01-30     39\n",
      "\n",
      "Number of campaigns with positive contribution: \n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "## stats \n",
    "\n",
    "dataset = \"gn_fb_tonic\"\n",
    "print(f\"Dataset: {dataset}\")\n",
    "# Total number of campaigns\n",
    "print(f\"Total number of campaigns: {series.ad_id.nunique()}\")\n",
    "# Ads starting from date ... \n",
    "print(f\"Min eventdate: {series.eventdate.min().date()}\") \n",
    "print(f\"Max eventdate: {series.eventdate.max().date()}\")\n",
    "days_between = (series.eventdate.max().date() - series.eventdate.min().date()).days\n",
    "print(f\"Days between min and max eventdate: {days_between}\")\n",
    "print()\n",
    "# Duration of campaigns \n",
    "campaign_duration_count = series.groupby([\"ad_id\", \"campaign_duration\"]).size().value_counts().sort_index().reset_index(name='count').rename(columns={'index':'campaign_duration (days)'})\n",
    "print(f\"Duration of campaigns (filtered to only campaigns of {min_campaign_duration} or more days): \\n{campaign_duration_count}\")\n",
    "print()\n",
    "# mean campaign duration \n",
    "print(f\"Mean campaign duration: {series.campaign_duration.mean().round(1)} days\")\n",
    "\n",
    "series['fb_created_date'] = pd.to_datetime(series['fb_created']).dt.date\n",
    "print()\n",
    "\n",
    "# number of unique ad_ids per date \n",
    "campaigns_created_per_date = series.groupby('fb_created_date').ad_id.nunique().reset_index(name='count').sort_values('fb_created_date', ascending=True)\n",
    "print(f\"Number of campaigns created per date: \\n {campaigns_created_per_date}\")\n",
    "positive_contrib_ads = series.groupby('ad_id')['contrib'].sum().reset_index()\n",
    "print()\n",
    "positive_contrib_ads = positive_contrib_ads[positive_contrib_ads['contrib'] > 0]['ad_id']\n",
    "print(f\"Number of campaigns with positive contribution: \\n {positive_contrib_ads.nunique()}\")\n",
    "# print(positive_contrib_ads)\n",
    "# peek(series[series['ad_id'].isin(positive_contrib_ads[positive_contrib_ads['contrib'] > 0]['ad_id'])])\n",
    "\n",
    "# peek(series[series['ad_id'] == '120204217187110410'])\n",
    "\n",
    "\n",
    "# TODO\n",
    "\n",
    "# extended campaings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.6986301369863014\n",
      "val: 0.3013698630136986\n",
      "train ads: 102\n",
      "val ads: 44\n"
     ]
    }
   ],
   "source": [
    "# train/val split \n",
    "\n",
    "unique_ad_ids = series['ad_id'].unique()\n",
    "\n",
    "train_ad_ids, val_ad_ids = train_test_split(unique_ad_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "train = series[series['ad_id'].isin(train_ad_ids)]\n",
    "val = series[series['ad_id'].isin(val_ad_ids)]\n",
    "\n",
    "print(f\"train: {(train['ad_id'].nunique()/series['ad_id'].nunique())}\")\n",
    "print(f\"val: {val['ad_id'].nunique()/series['ad_id'].nunique()}\")\n",
    "\n",
    "print(f\"train ads: {train.ad_id.nunique()}\")\n",
    "print(f\"val ads: {val.ad_id.nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up timeseries for darts \n",
    "\n",
    "time_col = 'eventdate'\n",
    "group_cols = 'ad_id'\n",
    "static_cols = ['age_max',\n",
    "               'age_min',  \n",
    "                'network_[\"facebook\",\"instagram\"]',   \n",
    "                'network_[\"facebook\"]',\n",
    "                'devices_[\"mobile\",\"desktop\"]',\n",
    "                'devices_[\"mobile\"]'\n",
    "                ]\n",
    "\n",
    "# value_col = ['net_revenue', 'fb_spend']\n",
    "\n",
    "value_col = \"roas\"\n",
    "\n",
    "past_covariates = ['fb_spend', \n",
    "                   'fb_clicks_all',\n",
    "                   'fb_impressions',\n",
    "                   'fb_leads',\n",
    "                   'rev_clicks',\n",
    "                   'fb_link_click',                \n",
    "                   ]\n",
    "\n",
    "# future_covariates = [\"campaign_duration\"]\n",
    "\n",
    "\n",
    "train_ts = TimeSeries.from_group_dataframe(\n",
    "                            train,\n",
    "                            time_col= time_col,\n",
    "                            group_cols= group_cols,\n",
    "                            static_cols= static_cols,\n",
    "                            value_cols= value_col ,\n",
    "                            fill_missing_dates=True,                            \n",
    "                            freq='D')\n",
    "\n",
    "\n",
    "val_ts = TimeSeries.from_group_dataframe(\n",
    "                            val,\n",
    "                            time_col= time_col,\n",
    "                            group_cols= group_cols,\n",
    "                            static_cols= static_cols,\n",
    "                            value_cols= value_col ,\n",
    "                            fill_missing_dates=True,                            \n",
    "                            freq='D')\n",
    "\n",
    "\n",
    "past_covariates_ts = TimeSeries.from_group_dataframe(\n",
    "    train,\n",
    "    time_col=time_col,    \n",
    "    group_cols=group_cols,\n",
    "    static_cols= static_cols,\n",
    "    value_cols=past_covariates,\n",
    "    freq='D'  \n",
    ")\n",
    "\n",
    "\n",
    "past_covariates_vs = TimeSeries.from_group_dataframe(\n",
    "    val,\n",
    "    time_col=time_col,\n",
    "    group_cols=group_cols,\n",
    "     static_cols= static_cols,\n",
    "    value_cols=past_covariates,\n",
    "    freq='D'  \n",
    ")\n",
    "\n",
    "\n",
    "# fill missing values darts \n",
    "\n",
    "for i, ts in enumerate(train_ts):    \n",
    "    if not ts.gaps().empty:        \n",
    "        train_ts[i] = missing_values.fill_missing_values(ts)\n",
    "\n",
    "for i, ts in enumerate(val_ts):    \n",
    "    if not ts.gaps().empty:        \n",
    "        val_ts[i] = missing_values.fill_missing_values(ts)\n",
    "        \n",
    "for i, ts in enumerate(past_covariates_ts):    \n",
    "    if not ts.gaps().empty:        \n",
    "        past_covariates_ts[i] = missing_values.fill_missing_values(ts)\n",
    "\n",
    "for i, ts in enumerate(past_covariates_vs):    \n",
    "    if not ts.gaps().empty:        \n",
    "        past_covariates_vs[i] = missing_values.fill_missing_values(ts)\n",
    "\n",
    "\n",
    "\n",
    "transformer = StaticCovariatesTransformer()\n",
    "train_ts = transformer.fit_transform(train_ts)\n",
    "val_ts = transformer.fit_transform(val_ts)\n",
    "past_covariates_ts = transformer.fit_transform(past_covariates_ts)       \n",
    "past_covariates_vs = transformer.fit_transform(past_covariates_vs)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check missing values in timeseries\n",
    "\n",
    "# for i, ts in enumerate(past_covariates_ts):\n",
    "#     dataframe = ts.pd_dataframe()  # Convert each TimeSeries to a DataFrame\n",
    "#     has_nans = dataframe.isna().values.any()  # Check for NaN values\n",
    "#     print(f\"TimeSeries {i} contains NaN values? {has_nans}\")\n",
    "# nan_series = [dataframe.isna().any().any() for dataframe in [ts.pd_dataframe() for ts in all_campaigns_ts]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiment_params.yaml\", 'r') as stream:\n",
    "    try:\n",
    "        experiment_params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_global_model(\n",
    "    train_ts: List[TimeSeries],    \n",
    "    val_ts: List[TimeSeries],\n",
    "    val:pd.DataFrame,\n",
    "    model_cls,     \n",
    "    past_covariates_ts: List[TimeSeries],\n",
    "    past_covariates_vs: List[TimeSeries],    \n",
    "    model_params: dict,\n",
    "    forecast_params: dict,  \n",
    "   \n",
    "\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    \n",
    "    model = model_cls(**model_params)\n",
    "\n",
    "    if model_params.get(\"lags_past_covariates\") is not None:\n",
    "        model.fit(train_ts, past_covariates_ts)\n",
    "    else:\n",
    "        model.fit(train_ts)        \n",
    "    \n",
    "    backtest = model.historical_forecasts(\n",
    "                series = val_ts,\n",
    "                past_covariates = past_covariates_vs,                \n",
    "               **forecast_params\n",
    "               )\n",
    "    \n",
    "    unique_ad_ids = val['ad_id'].unique()\n",
    "    positions_df = pd.DataFrame({'ad_id': unique_ad_ids, 'position': range(len(unique_ad_ids))})\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i, series in enumerate(backtest):\n",
    "        backtest_ad_id = positions_df.iloc[i]['ad_id']\n",
    "        # Convert the TimeSeries object to a DataFrame\n",
    "        forecast_df = series.pd_dataframe().rename(columns={'roas': 'roas_forecasted'})\n",
    "        \n",
    "        # Merge the actual values with the forecasted values\n",
    "        temp_df = pd.merge(val[val['ad_id'] == backtest_ad_id].sort_values(by='eventdate')[['ad_id', 'eventdate', 'roas']].rename(columns={'roas': 'roas_actual'}),\n",
    "                        forecast_df, left_on='eventdate', right_index=True, how='left')\n",
    "        \n",
    "        # Calculate cumulative sums and residuals\n",
    "        temp_df['roas_act_cum'] = temp_df['roas_actual'].cumsum()\n",
    "        temp_df['roas_fcst_cum'] = temp_df['roas_forecasted'].cumsum()\n",
    "        temp_df['residuals'] = temp_df['roas_forecasted'] - temp_df['roas_actual']\n",
    "        \n",
    "        # Add model information\n",
    "        if model.__class__.__name__ == 'RegressionModel':\n",
    "            temp_df['model'] = model.model.__class__.__name__\n",
    "        else:\n",
    "            temp_df['model'] = model.__class__.__name__\n",
    "        temp_df['params'] = temp_df.apply(lambda x: {'model_params': model_params, 'forecast_params': forecast_params}, axis=1)\n",
    "        \n",
    "        # Append the results to the main DataFrame\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "    return df, backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forecast_plots(val_ts, backtest):\n",
    "    \n",
    "    num_plots = len(val_ts)\n",
    "    num_cols = 4\n",
    "    num_rows = num_plots // num_cols + (num_plots % num_cols > 0)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, figsize=(20, num_rows*5))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i < num_plots:\n",
    "            val_ts[i].plot(ax=ax, label='Actual ROAS')        \n",
    "            backtest[i].plot(ax=ax, label='Forecasted ROAS')            \n",
    "            ax.legend()\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    return fig    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_per_ad(\n",
    "    forecast: pd.DataFrame):\n",
    "    grouped = forecast.groupby('ad_id').agg(\n",
    "        # contrib=('roas_actual', 'sum'),\n",
    "        # predicted_contrib=('roas_forecasted', 'sum'),\n",
    "        cumulative_roas_actual=('roas_act_cum', 'last'),\n",
    "        cumulative_roas_predicted=('roas_fcst_cum', 'last'),\n",
    "        MAE=('residuals', lambda x: (x.abs()).mean()),\n",
    "        RMSE=('residuals', lambda x: ((x**2).mean())**0.5)\n",
    "    ).reset_index()\n",
    "    grouped.columns = [\n",
    "        'ad_id', \n",
    "        # 'contrib', \n",
    "        # 'predicted_contrib', \n",
    "        'cumulative_roas_actual', 'cumulative_roas_predicted', 'MAE', 'RMSE']\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "\n",
    "    (\"linear_reg\", LinearRegressionModel),\n",
    "    # (\"lgbm\", LightGBMModel),\n",
    "    (\"ridge\",Ridge),\n",
    "    (\"bayes_ridge\", BayesianRidge),\n",
    "    # (\"xgboost\",XGBModel),\n",
    "    # (\"catboost\", \"CatBoostModel\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_and_create_df(val_ts, backtest, model_params):\n",
    "    rmse_values = [rmse(val_ts[i], backtest[i]) for i in range(len(val_ts))]\n",
    "    mae_values = [mae(val_ts[i], backtest[i]) for i in range(len(val_ts))]\n",
    "\n",
    "    # Calculate metrics\n",
    "    average_rmse = np.mean(rmse_values)\n",
    "    median_rmse = np.median(rmse_values)\n",
    "    std_rmse = np.std(rmse_values)\n",
    "    average_mae = np.mean(mae_values)\n",
    "    median_mae = np.median(mae_values)\n",
    "    std_mae = np.std(mae_values)\n",
    "\n",
    "    # Create DataFrame\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Model Params': [model_params],\n",
    "        'MAE': [average_mae],\n",
    "        'RMSE': [average_rmse],\n",
    "        'Median MAE': [median_mae],\n",
    "        'Median RMSE': [median_rmse],\n",
    "        'Std MAE': [std_mae],\n",
    "        'Std RMSE': [std_rmse]\n",
    "    })\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(\n",
    "    model_list,    \n",
    "    train_ts: List[TimeSeries],    \n",
    "    val_ts: List[TimeSeries],\n",
    "    val: pd.DataFrame,     \n",
    "    past_covariates_ts: List[TimeSeries],\n",
    "    past_covariates_vs: List[TimeSeries],    \n",
    "    experiment_params: dict or list,\n",
    "):\n",
    "    results_forecasts_dict = {}\n",
    "    metrics_df = pd.DataFrame()      \n",
    "\n",
    "    if isinstance(experiment_params, dict):\n",
    "        experiment_params = [experiment_params]\n",
    "    \n",
    "    results_dir = \"exp_results\"\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    \n",
    "    for model_name, model_class in model_list:   \n",
    "        for params_set in experiment_params:\n",
    "            model_params = params_set.get('model_params', {})\n",
    "            forecast_params = params_set.get('forecast_params', {})\n",
    "\n",
    "            if model_class in [Ridge, BayesianRidge, LinearRegressionModel]: \n",
    "                for key in [\"categorical_static_covariates\", \"verbose\", \"likelihood\", \"quantiles\", \"random_state\"]:\n",
    "                    model_params.pop(key, None)\n",
    "            if model_class in [Ridge, BayesianRidge]: \n",
    "                model = RegressionModel\n",
    "                model_params['model'] = model_class()\n",
    "            else:\n",
    "                model = model_class\n",
    "            \n",
    "            forecast, backtest = eval_global_model(\n",
    "                train_ts,    \n",
    "                val_ts,\n",
    "                val,\n",
    "                model, \n",
    "                past_covariates_ts,\n",
    "                past_covariates_vs,    \n",
    "                model_params,\n",
    "                forecast_params\n",
    "            )\n",
    "            \n",
    "            params_set_name = f\"params_{experiment_params.index(params_set) + 1}\"\n",
    "            forecast.to_csv(f\"{results_dir}/{model_name}_{params_set_name}_forecast.csv\")\n",
    "            perf_per_ad(forecast).to_csv(f\"{results_dir}/{model_name}_{params_set_name}_results_per_ad.csv\")\n",
    "            with open(f\"{results_dir}/{model_name}_{params_set_name}_backtest.pkl\", 'wb') as f:\n",
    "                pickle.dump(backtest, f)\n",
    "\n",
    "            results_forecasts_dict[f\"{model_name}_{params_set_name}_forecast\"] = forecast\n",
    "            results_forecasts_dict[f\"{model_name}_{params_set_name}_backtest\"] = backtest\n",
    "            \n",
    "            fig = make_forecast_plots(val_ts, backtest)\n",
    "            fig.savefig(f\"{results_dir}/{model_name}_{params_set_name}_backtest.png\")\n",
    "\n",
    "            temp_metrics_df = calculate_metrics_and_create_df(val_ts, backtest, model_params)\n",
    "            temp_metrics_df['Model Name'] = model_name\n",
    "            temp_metrics_df['Params Set Name'] = params_set_name\n",
    "            metrics_df = pd.concat([metrics_df, temp_metrics_df], ignore_index=True)\n",
    "            plt.close(fig)\n",
    "\n",
    "            shap_explain = ShapExplainer(model, train_ts, past_covariates_ts)\n",
    "            fig=plt.gcf()\n",
    "            shap_explain.summary_plot(show=False,)\n",
    "            fig.savefig(f\"{results_dir}/{model_name}_{params_set_name}_shap_summary.png\")\n",
    "            plt.close('all')\n",
    "\n",
    "    return results_forecasts_dict, metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_forecasts_dict, metrics_df = run_experiments(\n",
    "#     model_list,\n",
    "#     train_ts,\n",
    "#     val_ts,\n",
    "#     val,\n",
    "#     past_covariates_ts,\n",
    "#     past_covariates_vs,\n",
    "#     experiment_params,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
